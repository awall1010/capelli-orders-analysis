{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7b19a3",
   "metadata": {},
   "source": [
    "## Overview  \n",
    "This notebook (`OrderGrouping.ipynb`) automates the weekly aggregation of Capelli’s “Details” CSV export into a single summary file. It performs the following high-level steps: loading and preprocessing the raw CSV, cleaning column names and types, converting date and quantity fields, grouping by **Customer Reference** and **Club Name**, applying custom aggregation logic for order status, and writing the result to a new CSV.  \n",
    "\n",
    "## What You Need to Update Weekly  \n",
    "1. **Input file path**:  \n",
    "   - In the **Main Execution** block, set `input_file` to point at the latest Capelli “Details” tab CSV, e.g.  \n",
    "     ```python\n",
    "     input_file = 'shippingdates/Rush Soccer <MM.DD> - Details.csv'\n",
    "     ```  \n",
    "   - This path should match the filename you download from the Capelli portal.  \n",
    "2. **Output file path**:  \n",
    "   - Also in **Main Execution**, set `output_file` to the desired aggregated filename, for example:  \n",
    "     ```python\n",
    "     output_file = 'shippingdates/aggregated_orders<MM.DD>.csv'\n",
    "     ```  \n",
    "   - The script will overwrite or create this file each run.  \n",
    "\n",
    "> **Note:** Both file paths live under the `shippingdates/` folder and must be updated to reflect the new report dates each week.  \n",
    "\n",
    "## How It Works  \n",
    "\n",
    "1. **Load & Preprocess**  \n",
    "   - Uses `pd.read_csv()` with error handling to catch missing or malformed files (`pd.read_csv` docs) :contentReference[oaicite:0]{index=0}.  \n",
    "   - Renames the “Shipped Date” column to **Shipping Date**, strips whitespace from all column names, and converts common missing-value strings (`'N/A'`) to `pd.NA`.  \n",
    "   - Converts date columns (`Date Created`, `Shipping Date`) into `datetime64[ns]` via `pd.to_datetime()` :contentReference[oaicite:1]{index=1}.  \n",
    "   - Converts quantity fields (`Order Quantity`, `Shipped Quantity`, `Unshipped Quantity`) to numeric, coercing invalid entries to `NaN` and then filling with the column median :contentReference[oaicite:2]{index=2}.  \n",
    "\n",
    "2. **Aggregation Logic**  \n",
    "   - Groups data by `['Customer Reference', 'Club Name']`.  \n",
    "   - For each group:  \n",
    "     - **Date Created**: takes the earliest date.  \n",
    "     - Quantity fields: sums across the group.  \n",
    "     - **Shipping Date**: takes the latest date.  \n",
    "     - **Sales Order Header Status**: uses a custom function that returns `'OPEN'` if *any* order in the group is open; otherwise it returns the mode (most frequent status).  \n",
    "\n",
    "3. **Save Results**  \n",
    "   - Writes the aggregated `DataFrame` to CSV using `DataFrame.to_csv()` in the `shippingdates/` directory :contentReference[oaicite:3]{index=3}.  \n",
    "\n",
    "## Usage Instructions  \n",
    "1. **Place your new Capelli export** (the Details tab) into `shippingdates/` with a clear filename (e.g., `Rush Soccer 05.11 - Details.csv`).  \n",
    "2. **Open this notebook**, update the `input_file` and `output_file` variables in the **Main Execution** cell.  \n",
    "3. **Run all cells** in order:  \n",
    "   - Data loading & preprocessing → aggregation → CSV export.  \n",
    "4. **Verify** that `shippingdates/aggregated_orders<MM.DD>.csv` appears and contains the summarized orders.  \n",
    "\n",
    "---  \n",
    "*By following these steps and updating only the two file-path variables each week, this notebook provides a reliable, repeatable process for consolidating weekly Capelli orders into a single, clean CSV for downstream analysis.*  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89591a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "First 5 rows of the dataset:\n",
      "\n",
      "Column Names:\n",
      "Index(['Customer Reference', 'Club Name', 'Date Created', 'Sold TO Name',\n",
      "       'Sold TO Email', 'Ship TO Name', 'Order Quantity', 'Shipped Quantity',\n",
      "       'Unshipped Quantity', 'Shipped Date', 'Tracking Number',\n",
      "       'Sales Order Header Status', 'Material Code', 'Description', 'Size'],\n",
      "      dtype='object')\n",
      "\n",
      "Data Types:\n",
      "Customer Reference            int64\n",
      "Club Name                    object\n",
      "Date Created                 object\n",
      "Sold TO Name                 object\n",
      "Sold TO Email                object\n",
      "Ship TO Name                 object\n",
      "Order Quantity                int64\n",
      "Shipped Quantity              int64\n",
      "Unshipped Quantity            int64\n",
      "Shipped Date                 object\n",
      "Tracking Number              object\n",
      "Sales Order Header Status    object\n",
      "Material Code                object\n",
      "Description                  object\n",
      "Size                         object\n",
      "dtype: object\n",
      "\n",
      "Cleaned Column Names:\n",
      "Index(['Customer Reference', 'Club Name', 'Date Created', 'Sold TO Name',\n",
      "       'Sold TO Email', 'Ship TO Name', 'Order Quantity', 'Shipped Quantity',\n",
      "       'Unshipped Quantity', 'Shipped Date', 'Tracking Number',\n",
      "       'Sales Order Header Status', 'Material Code', 'Description', 'Size'],\n",
      "      dtype='object')\n",
      "\n",
      "Data Types After Conversion:\n",
      "Customer Reference            int64\n",
      "Club Name                    object\n",
      "Date Created                 object\n",
      "Sold TO Name                 object\n",
      "Sold TO Email                object\n",
      "Ship TO Name                 object\n",
      "Order Quantity                int64\n",
      "Shipped Quantity              int64\n",
      "Unshipped Quantity            int64\n",
      "Shipped Date                 object\n",
      "Tracking Number              object\n",
      "Sales Order Header Status    object\n",
      "Material Code                object\n",
      "Description                  object\n",
      "Size                         object\n",
      "dtype: object\n",
      "\n",
      "Date Columns After Conversion:\n",
      "  Date Created Shipped Date\n",
      "0   2024-07-24   2024-08-14\n",
      "1   2024-07-24   2024-09-30\n",
      "2   2024-07-24   2024-09-30\n",
      "3   2024-07-24   2024-09-30\n",
      "4   2024-07-24   2024-09-30\n",
      "\n",
      "Number of rows with invalid 'Shipped Date': 4817\n",
      "Number of rows after removing invalid 'Shipped Date': 194014\n",
      "\n",
      "Sample 'Month-Year' Entries:\n",
      "  Shipped Date      Month-Year\n",
      "0   2024-08-14     August 2024\n",
      "1   2024-09-30  September 2024\n",
      "2   2024-09-30  September 2024\n",
      "3   2024-09-30  September 2024\n",
      "4   2024-09-30  September 2024\n",
      "\n",
      "Number of unique packages after removing duplicates: 36080\n",
      "\n",
      "Number of Packages Shipped Each Month:\n",
      "        Month-Year  Unique Packages Shipped\n",
      "6     January 2024                     1143\n",
      "4    February 2024                     2705\n",
      "10      March 2024                     2169\n",
      "0       April 2024                     1198\n",
      "12        May 2024                      857\n",
      "9        June 2024                     2977\n",
      "8        July 2024                     4817\n",
      "2      August 2024                     5216\n",
      "16  September 2024                     3596\n",
      "15    October 2024                     3198\n",
      "14   November 2024                     1129\n",
      "3    December 2024                     1361\n",
      "7     January 2025                     1348\n",
      "5    February 2025                     1634\n",
      "11      March 2025                     1514\n",
      "1       April 2025                     1201\n",
      "13        May 2025                       16\n",
      "\n",
      "Aggregated data saved to packages_shipped_per_month.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------- Step 1: Load the Data -------------------------- #\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'shippingdates/Rush Soccer 5.4 - Details.csv'  # Replace with your actual file path\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "# Assuming the CSV is tab-separated based on the sample data\n",
    "try:\n",
    "    # Instead of sep='\\t', just let pandas infer commas:\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    print(\"Data loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "\n",
    "# -------------------------- Step 2: Inspect the Data -------------------------- #\n",
    "\n",
    "# Display the first few rows to understand the data structure\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "# print(df.head())\n",
    "\n",
    "# Display the column names and their data types\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns)\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# -------------------------- Step 3: Clean Column Names -------------------------- #\n",
    "\n",
    "# Strip leading and trailing whitespace from all column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Verify column names after stripping\n",
    "print(\"\\nCleaned Column Names:\")\n",
    "print(df.columns)\n",
    "\n",
    "# -------------------------- Step 4: Clean Specific Columns -------------------------- #\n",
    "\n",
    "# Define columns that may contain whitespace and need to be stripped\n",
    "columns_to_strip = ['Order Quantity', 'Shipped Quantity', 'Unshipped Quantity']\n",
    "\n",
    "# Strip whitespace from these columns if they are of object type (strings)\n",
    "df[columns_to_strip] = df[columns_to_strip].apply(\n",
    "    lambda x: x.str.strip() if x.dtype == \"object\" else x\n",
    ")\n",
    "\n",
    "# Convert 'Shipped Quantity' and 'Unshipped Quantity' to numeric types\n",
    "# Replace non-numeric entries with 0\n",
    "df['Shipped Quantity'] = pd.to_numeric(df['Shipped Quantity'], errors='coerce').fillna(0).astype(int)\n",
    "df['Unshipped Quantity'] = pd.to_numeric(df['Unshipped Quantity'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Verify the changes\n",
    "print(\"\\nData Types After Conversion:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# -------------------------- Step 5: Convert Date Columns -------------------------- #\n",
    "\n",
    "# Convert 'Date Created' and 'Shipped Date' to datetime format\n",
    "# Coerce errors to NaT (Not a Time) for invalid dates\n",
    "df['Date Created'] = pd.to_datetime(df['Date Created'], errors='coerce', format='%m/%d/%Y')\n",
    "df['Shipped Date'] = pd.to_datetime(df['Shipped Date'], errors='coerce', format='%m/%d/%Y')\n",
    "\n",
    "# Verify the conversion\n",
    "print(\"\\nDate Columns After Conversion:\")\n",
    "print(df[['Date Created', 'Shipped Date']].head())\n",
    "\n",
    "# -------------------------- Step 6: Handle Invalid 'Shipped Date' Entries -------------------------- #\n",
    "\n",
    "# Identify rows with invalid 'Shipped Date' (NaT)\n",
    "invalid_shipping_dates = df['Shipped Date'].isna()\n",
    "print(f\"\\nNumber of rows with invalid 'Shipped Date': {invalid_shipping_dates.sum()}\")\n",
    "\n",
    "# Option 1: Remove rows with invalid 'Shipped Date'\n",
    "df_clean = df.dropna(subset=['Shipped Date']).copy()\n",
    "print(f\"Number of rows after removing invalid 'Shipped Date': {df_clean.shape[0]}\")\n",
    "\n",
    "# Optionally, you can choose to fill invalid 'Shipped Date' with 'Date Created' or another default date\n",
    "# Uncomment the following lines if you prefer this approach\n",
    "# df['Shipped Date'] = df['Shipped Date'].fillna(df['Date Created'])\n",
    "# df_clean = df.dropna(subset=['Shipped Date']).copy()\n",
    "\n",
    "# -------------------------- Step 7: Extract Month-Year from 'Shipped Date' -------------------------- #\n",
    "\n",
    "# Create a new column 'Month-Year' in 'MMMM YYYY' format (e.g., July 2024)\n",
    "df_clean['Month-Year'] = df_clean['Shipped Date'].dt.strftime('%B %Y')\n",
    "\n",
    "# Verify the new column\n",
    "print(\"\\nSample 'Month-Year' Entries:\")\n",
    "print(df_clean[['Shipped Date', 'Month-Year']].head())\n",
    "\n",
    "# -------------------------- Step 8: Remove Duplicate Tracking Numbers -------------------------- #\n",
    "\n",
    "# Assuming each 'Tracking Number' uniquely identifies a package, remove duplicates\n",
    "# If 'Tracking Number' is not unique per package, adjust accordingly\n",
    "df_unique = df_clean.drop_duplicates(subset=['Tracking Number'])\n",
    "\n",
    "# Verify the removal of duplicates\n",
    "print(f\"\\nNumber of unique packages after removing duplicates: {df_unique.shape[0]}\")\n",
    "\n",
    "# -------------------------- Step 9: Group by 'Month-Year' and Count Unique Packages -------------------------- #\n",
    "\n",
    "# Group by 'Month-Year' and count unique 'Tracking Number' to get the number of packages shipped each month\n",
    "packages_shipped = df_unique.groupby('Month-Year')['Tracking Number'].nunique().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "packages_shipped.columns = ['Month-Year', 'Unique Packages Shipped']\n",
    "\n",
    "# -------------------------- Step 10: Sort the Results Chronologically -------------------------- #\n",
    "\n",
    "# Convert 'Month-Year' back to datetime for sorting\n",
    "packages_shipped['Month-Year-Date'] = pd.to_datetime(packages_shipped['Month-Year'], format='%B %Y')\n",
    "\n",
    "# Sort by the new datetime column\n",
    "packages_shipped = packages_shipped.sort_values('Month-Year-Date')\n",
    "\n",
    "# Drop the auxiliary datetime column\n",
    "packages_shipped = packages_shipped.drop('Month-Year-Date', axis=1)\n",
    "\n",
    "# -------------------------- Step 11: Display the Results -------------------------- #\n",
    "\n",
    "print(\"\\nNumber of Packages Shipped Each Month:\")\n",
    "print(packages_shipped)\n",
    "\n",
    "# -------------------------- Step 12: (Optional) Save the Results to CSV -------------------------- #\n",
    "\n",
    "# Define the output file path\n",
    "output_file = 'packages_shipped_per_month.csv'\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "packages_shipped.to_csv(output_file, index=False)\n",
    "print(f\"\\nAggregated data saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
